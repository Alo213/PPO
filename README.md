# PPO
Este repositorio es una implementación funcional lo más simple posible del algoritmo [Proximal Policy Optimization](https://arxiv.org/abs/1707.06347) de aprendizaje reforzado. Esta implementación fue hecha tomando como base el [blog](https://medium.com/analytics-vidhya/coding-ppo-from-scratch-with-pytorch-part-1-4-613dfc1b14c8) de Eric Yang Yu @ UC San Diego.
